{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Scribe Handwriting Synthesis - Colab Training\n",
    "\n",
    "Train a handwriting synthesis model on Google Colab Pro with GPU acceleration.\n",
    "\n",
    "**Requirements:**\n",
    "- Google Colab Pro subscription ($10/month)\n",
    "- ~15 GB Google Drive space for data + checkpoints\n",
    "- GPU runtime (T4/V100/A100)\n",
    "\n",
    "**Expected training time:** 3-6 hours (250 epochs with rnn_size=400)\n",
    "\n",
    "**Important:** This notebook saves all outputs to Google Drive for persistence across sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## 1. Install TensorFlow 2.15 and Dependencies\n",
    "\n",
    "Colab comes with TensorFlow 2.19 by default, but Scribe requires TensorFlow 2.15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install TensorFlow 2.15 and required dependencies\n",
    "!pip install -q tensorflow==2.15.0 numpy==1.26.4 svgwrite==1.4.3 matplotlib==3.8.2\n",
    "\n",
    "print(\"‚úì Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify-header"
   },
   "source": [
    "## 2. Verify Installation and GPU\n",
    "\n",
    "Check that TensorFlow 2.15 is installed correctly and GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify-gpu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"\\n‚úì GPU available: {gpus[0].name}\")\n",
    "    # Enable memory growth to prevent OOM errors on T4\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"‚úì GPU memory growth enabled\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: No GPU detected!\")\n",
    "    print(\"Go to Runtime > Change runtime type > Hardware accelerator > GPU\")\n",
    "\n",
    "print(f\"\\n‚úì Setup verification complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mount-header"
   },
   "source": [
    "## 3. Mount Google Drive and Setup Directories\n",
    "\n",
    "All project files and outputs will be saved to Google Drive for persistence.\n",
    "\n",
    "**Before running this cell:**\n",
    "1. Upload the entire `scribe` folder to your Google Drive root\n",
    "2. Ensure `data/strokes_training_data.cpkl` is present (44 MB)\n",
    "3. Ensure `data/styles/` directory contains 26 .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define project paths\n",
    "PROJECT_DIR = '/content/drive/MyDrive/scribe'\n",
    "DATA_DIR = f'{PROJECT_DIR}/data'\n",
    "SAVED_DIR = f'{PROJECT_DIR}/saved'\n",
    "LOGS_DIR = f'{PROJECT_DIR}/logs'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(SAVED_DIR, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "os.makedirs(f'{LOGS_DIR}/figures', exist_ok=True)\n",
    "\n",
    "print(f\"‚úì Google Drive mounted\")\n",
    "print(f\"‚úì Project directory: {PROJECT_DIR}\")\n",
    "print(f\"‚úì Output directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify-files-header"
   },
   "source": [
    "## 4. Verify Required Files\n",
    "\n",
    "Check that all necessary files are present before starting training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify-files"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check critical files\n",
    "required_files = [\n",
    "    f'{PROJECT_DIR}/train.py',\n",
    "    f'{PROJECT_DIR}/model.py',\n",
    "    f'{PROJECT_DIR}/utils.py',\n",
    "    f'{DATA_DIR}/strokes_training_data.cpkl',\n",
    "]\n",
    "\n",
    "all_present = True\n",
    "for filepath in required_files:\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath)\n",
    "        print(f\"‚úì {os.path.basename(filepath)} ({size:,} bytes)\")\n",
    "    else:\n",
    "        print(f\"‚úó MISSING: {filepath}\")\n",
    "        all_present = False\n",
    "\n",
    "# Check style files\n",
    "styles_dir = f'{DATA_DIR}/styles'\n",
    "if os.path.exists(styles_dir):\n",
    "    style_files = [f for f in os.listdir(styles_dir) if f.endswith('.npy')]\n",
    "    print(f\"\\n‚úì Found {len(style_files)} style files\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: Styles directory not found\")\n",
    "\n",
    "if all_present:\n",
    "    print(\"\\n‚úì All required files present - ready to train!\")\n",
    "else:\n",
    "    print(\"\\n‚úó ERROR: Missing required files - please upload the scribe folder to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify-data-header"
   },
   "source": [
    "## 5. Verify Training Data\n",
    "\n",
    "Run the data verification script to ensure the dataset is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify-data"
   },
   "outputs": [],
   "source": [
    "%cd {PROJECT_DIR}\n",
    "!python verify_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train-header"
   },
   "source": [
    "## 6. Start Training\n",
    "\n",
    "Train with recommended parameters for style priming support:\n",
    "- `rnn_size=400` (required for style priming)\n",
    "- `nmixtures=20` (high quality output)\n",
    "- `nepochs=250` (full training)\n",
    "- `save_every=250` (more frequent checkpoints for Colab)\n",
    "\n",
    "**Expected training time:** 3-6 hours on T4/V100 GPU\n",
    "\n",
    "**Note:** If the session disconnects, simply re-run this cell. The script automatically resumes from the latest checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train"
   },
   "outputs": [],
   "source": [
    "%cd {PROJECT_DIR}\n",
    "\n",
    "!python train.py \\\n",
    "    --rnn_size 400 \\\n",
    "    --nmixtures 20 \\\n",
    "    --nepochs 250 \\\n",
    "    --batch_size 32 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --save_every 250 \\\n",
    "    --data_dir {DATA_DIR} \\\n",
    "    --save_path {SAVED_DIR}/model \\\n",
    "    --log_dir {LOGS_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monitor-header"
   },
   "source": [
    "## 7. Monitor Training Progress (Optional)\n",
    "\n",
    "Watch the training log in real-time. Run this in a separate cell while training is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "monitor"
   },
   "outputs": [],
   "source": [
    "# View the latest log file\n",
    "!tail -f {LOGS_DIR}/*.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sample-header"
   },
   "source": [
    "## 8. Generate Samples After Training\n",
    "\n",
    "Test the trained model by generating handwriting samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sample"
   },
   "outputs": [],
   "source": [
    "%cd {PROJECT_DIR}\n",
    "\n",
    "# Generate basic sample\n",
    "!python sample.py \\\n",
    "    --text \"The quick brown fox jumps over the lazy dog. 1234567890\" \\\n",
    "    --bias 1.0 \\\n",
    "    --format svg \\\n",
    "    --save_path {SAVED_DIR}/model\n",
    "\n",
    "# Generate multi-line sample with styles\n",
    "!python sample.py \\\n",
    "    --lines \"Dear friend, I hope this finds you well.\" \\\n",
    "            \"The meeting is scheduled for 3:00pm on June 15th.\" \\\n",
    "            \"Looking forward to seeing you soon!\" \\\n",
    "    --biases 1.2 1.0 1.2 \\\n",
    "    --styles 0 3 0 \\\n",
    "    --format svg \\\n",
    "    --save_path {SAVED_DIR}/model\n",
    "\n",
    "print(f\"\\n‚úì Samples generated in {LOGS_DIR}/figures/\")\n",
    "print(\"View them in Google Drive or download below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-header"
   },
   "source": [
    "## 9. Download Results (Optional)\n",
    "\n",
    "Download checkpoints and samples directly from Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import glob\n",
    "\n",
    "# Option 1: Download latest checkpoint\n",
    "print(\"Available checkpoints:\")\n",
    "checkpoints = glob.glob(f'{SAVED_DIR}/checkpoint-*')\n",
    "for cp in sorted(checkpoints)[-5:]:\n",
    "    print(f\"  {os.path.basename(cp)}\")\n",
    "\n",
    "# Option 2: Download generated SVG samples\n",
    "print(\"\\nGenerated samples:\")\n",
    "samples = glob.glob(f'{LOGS_DIR}/figures/*.svg')\n",
    "for sample in sorted(samples)[-5:]:\n",
    "    print(f\"  {os.path.basename(sample)}\")\n",
    "\n",
    "# Uncomment to download the latest sample:\n",
    "# if samples:\n",
    "#     latest_sample = sorted(samples)[-1]\n",
    "#     files.download(latest_sample)\n",
    "#     print(f\"\\n‚úì Downloaded: {os.path.basename(latest_sample)}\")\n",
    "\n",
    "print(\"\\nüí° Tip: All files are saved to Google Drive and persist across sessions\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Scribe Handwriting Synthesis Training",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
